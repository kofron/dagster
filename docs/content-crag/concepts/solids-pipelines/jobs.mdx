---
title: Jobs | Dagster
description: A job is a graph plus a set of resources and configuration.
---

# Jobs

A job is a set of ops plus a set of resources and configuration.

## Relevant APIs

| Name                                                  | Description                                                                                                                                                                                                    |
| ----------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <PyObject object="job" />                             | The decorator used to create a job.                                                                                                                                                                            |
| <PyObject object="GraphDefinition" method="to_job" /> | The method used to create a job from a graph.                                                                                                                                                                  |
| <PyObject object="JobDefinition" />                   | A job definition.  Includes a graph, [resources](/concepts/resources), default [configuration](/concepts/configuration/config-schema), tags, [hooks](/concepts/solids-pipelines/solid-hooks), and an executor. |

Dagster is built around the observation that any data DAG typically contains a logical core of transformation (the graph), which is reusable across a set of environments or scenarios. The graph usually needs to be "customized" for each environment, by plugging in configuration and services that are specific to that environment.

A Dagster _job_ is the combination of a set of ops organized into a logical graph and a set of [resources](/concepts/resources) and [configuration](/concepts/configuration/config-schema).

Jobs are the unit of execution and monitoring in Dagster deployments - the [Dagit UI](/concepts/dagit/dagit) centers on jobs.  Dagit makes it easy to view all the runs of each job in one place, as well as to manually kick off runs for a job.

You can define [schedules](/concepts/partitions-schedules-sensors/schedules) to execute jobs at fixed intervals or define [sensors](/concepts/partitions-schedules-sensors/sensors) to trigger them jobs when external changes occur. You can also launch jobs manually from Dagit, GraphQL APIs, or the command line.

## Creating a job

### From scratch

The simplest way of creating a job is to use the <PyObject object="job"/> decorator.
Within the decorated function body, you can use function calls to indicate the dependency structure between the ops/graphs.

```python file=/concepts/solids_pipelines/simple_job.py
from dagster import op, job


@op
def do_something():
    pass


@job
def do_stuff():
    do_something()
```

If you want to supply resources, config, tags, hooks, or an executor to a job, you can do this via the arguments to the <PyObject object="job"/> decorator.

```python file=/concepts/solids_pipelines/jobs.py
from dagster import ResourceDefinition, job, op


@op(config_schema={"config_param": str}, required_resource_keys={"my_resource"})
def do_something(context):
    context.log.info("config_param: " + context.op_config["config_param"])
    context.log.info("my_resource: " + context.resources.my_resource)


@job(
    config={"ops": {"do_something": {"config": {"config_param": "stuff"}}}},
    resource_defs={"my_resource": ResourceDefinition.hardcoded_resource("hello")},
)
def do_it_all():
    do_something()
```

### From a graph

As stated earlier, a job consists of an underlying computation graph, and an execution environment. When you want to run the same set of ops within different execution environments (ie prod, local, staging), then it's useful to be able to re-use the same underlying computation graph for multiple jobs.
To do this, we can use the `@graph` decorator to define the underlying computation graph (learn more about graphs on the [Graph Concepts Page](/concepts/solids-pipelines/pipelines.mdx)).

```python file=/concepts/solids_pipelines/jobs_from_graphs.py startafter=start_define_graph endbefore=end_define_graph
from dagster import op, graph


@op(required_resource={"server"})
def interact_with_server():
    ...


@graph
def do_stuff():
    interact_with_server()
```

We can construct jobs from the computation graph using the <PyObject object="GraphDefinition" method="to_job" /> method on the graph.

```python file=/concepts/solids_pipelines/jobs_from_graphs.py startafter=start_define_jobs endbefore=end_define_jobs
prod_job = do_stuff.to_job(name="do_stuff_prod", resource_defs={"server": prod_server})
staging_job = do_stuff.to_job(name="do_stuff_staging", resource_defs={"server": staging_server})
local_job = do_stuff.to_job(NAME="do_stuff_local", resource_defs={"local": })
```

## Including a job in a repository

You make jobs available to Dagit, GraphQLs, and the command line by including them inside [repositories](/concepts/repositories-workspaces/repositories). If you include schedules or sensors in a repository, the repository will automatically include jobs that those schedules or sensors target.

```python file=/concepts/solids_pipelines/repo_with_job.py
from dagster import repository

from .jobs import do_it_all_job


@repository
def my_repo():
    return [do_it_all_job]
```

## Advanced job configuration

Ops and resources often accept [configuration](/concepts/configuration/config-schema) that determines how they behave. By default, you supply configuration for these ops and resources at the time you launch the job.

When constructing a job, you can customize how that configuration will be satisfied, by passing a value to the `config` parameter of the <PyObject object="GraphDefinition" method="to_job" /> method.  The options are discussed below:

### Hardcoded configuration

You can supply a config dictionary to the `config` argument of the <PyObject object="job"/> decorator. The supplied dictionary will be used to configure the job whenever the job is launched. It will show up in the Dagit Playground and can be overridden.

```python file=/concepts/solids_pipelines/jobs_with_default_config.py
from dagster import job, op


@op(config_schema={"config_param": str})
def do_something(context):
    context.log.info("config_param: " + context.op_config["config_param"])


default_config = {"ops": {"do_something": {"config": {"config_param": "stuff"}}}}


@job(config=default_config)
def do_it_all():
    do_something()


if __name__ == "__main__":
    # Will log "config_param: stuff"
    do_it_all.execute_in_process()
```

### Partitioned jobs

You can supply a <PyObject object="PartitionedConfig" /> to the `config` argument of the <PyObject object="job"/> decorator. It defines a discrete set of "partitions", along with a function for generating config for a partition. You can configure a job run by selecting a partition.

For more information on how this works, take a look at the [Partitions concept page](/concepts/partitions-schedules-sensors/partitions).

### Config mapping

You can supply a <PyObject object="ConfigMapping" /> to the `config` argument of <PyObject object="job" />. This allows you to expose a narrower config interface to your job.  Instead of needing to configure every op and resource individually when launching the job, you can supply a smaller number of values to the outer config, and the <PyObject object="ConfigMapping" /> can translate it into config for all the job's ops and resources.

```python file=/concepts/solids_pipelines/jobs_with_config_mapping.py
from dagster import config_mapping, job, op


@op(config_schema={"config_param": str})
def do_something(context):
    context.log.info("config_param: " + context.op_config["config_param"])


@config_mapping(config_schema={"simplified_param": str})
def simplified_config(val):
    return {"ops": {"do_something": {"config": {"config_param": val["simplified_param"]}}}}


@job(config=simplified_config)
def do_it_all():
    do_something()


if __name__ == "__main__":
    # Will log "config_param: stuff"
    do_it_all_with_simplified_config.execute_in_process(run_config={"simplified_param": "stuff"})
```
